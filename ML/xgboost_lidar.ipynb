{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91c46e9-f518-4197-a057-868165dc98e7",
   "metadata": {},
   "source": [
    "## Create ML model using XGBOOST algorithm for self-driving car with LIDAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe33f92-aaa6-400f-8fca-92245687345d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# from micromlgen import port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5263f22-6414-4800-805a-dbfe9a602d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read data from csv\n",
    "data = pd.read_csv('../data/test4567.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c648a2-82e2-4eb1-8e3c-da476133a687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>224</td>\n",
       "      <td>225</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>232</td>\n",
       "      <td>234</td>\n",
       "      <td>236</td>\n",
       "      <td>239</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>215</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218</td>\n",
       "      <td>221</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>225</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>231</td>\n",
       "      <td>233</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>216</td>\n",
       "      <td>217</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212</td>\n",
       "      <td>218</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>217</td>\n",
       "      <td>218</td>\n",
       "      <td>220</td>\n",
       "      <td>222</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "      <td>199</td>\n",
       "      <td>200</td>\n",
       "      <td>202</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "      <td>207</td>\n",
       "      <td>209</td>\n",
       "      <td>...</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>201</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>195</td>\n",
       "      <td>192</td>\n",
       "      <td>189</td>\n",
       "      <td>187</td>\n",
       "      <td>184</td>\n",
       "      <td>182</td>\n",
       "      <td>179</td>\n",
       "      <td>177</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18479</th>\n",
       "      <td>199</td>\n",
       "      <td>211</td>\n",
       "      <td>219</td>\n",
       "      <td>228</td>\n",
       "      <td>238</td>\n",
       "      <td>249</td>\n",
       "      <td>260</td>\n",
       "      <td>273</td>\n",
       "      <td>287</td>\n",
       "      <td>303</td>\n",
       "      <td>...</td>\n",
       "      <td>162</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>155</td>\n",
       "      <td>159</td>\n",
       "      <td>163</td>\n",
       "      <td>168</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18480</th>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>166</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>155</td>\n",
       "      <td>159</td>\n",
       "      <td>163</td>\n",
       "      <td>168</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18481</th>\n",
       "      <td>165</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>176</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18482</th>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18483</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>176</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18484 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9  ...  231  232  233  \\\n",
       "0      221  224  225  227  229  230  232  234  236  239  ...  211  212  212   \n",
       "1      218  221  222  222  225  227  229  231  233  235  ...  211  211  216   \n",
       "2      212  218  215  215  217  218  220  222  224  224  ...  202  202  202   \n",
       "3      193  196  197  199  200  202  204  205  207  209  ...  183  183  184   \n",
       "4      185  187  188  190  191  193  195  197  197  201  ...  202  195  192   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "18479  199  211  219  228  238  249  260  273  287  303  ...  162  155  157   \n",
       "18480  165  166  167  168  169  170  171  172  173  175  ...  166  155  157   \n",
       "18481  165  163  164  165  165  166  166  167  168  168  ...  178  177  176   \n",
       "18482  182  183  184  185  186  187  188  189  190  191  ...  180  179  179   \n",
       "18483  179  181  182  183  184  184  187  188  190  191  ...  174  174  174   \n",
       "\n",
       "       234  235  236  237  238  239  Label  \n",
       "0      212  212  213  214  214  215      F  \n",
       "1      217  210  211  211  212  213      F  \n",
       "2      203  203  204  204  204  205      F  \n",
       "3      184  185  185  186  187  187      F  \n",
       "4      189  187  184  182  179  177      I  \n",
       "...    ...  ...  ...  ...  ...  ...    ...  \n",
       "18479  159  151  155  159  163  168      F  \n",
       "18480  159  151  155  159  163  168      G  \n",
       "18481  175  174  173  173  172  172      I  \n",
       "18482  179  179  179  179  179  179      F  \n",
       "18483  174  174  175  175  175  176      F  \n",
       "\n",
       "[18484 rows x 241 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rename(columns={data.columns[-1]: 'Label'}, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7e28a4-a455-4b12-a92e-5e0f8acd2e31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'I', 'G', 'R', 'L', 'H'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the original data that will contain L, R, and H which are unwanted as we want the car is always drive forward\n",
    "data['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d739e89-f898-4965-8237-c3c983fc09b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>224</td>\n",
       "      <td>225</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>232</td>\n",
       "      <td>234</td>\n",
       "      <td>236</td>\n",
       "      <td>239</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>215</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218</td>\n",
       "      <td>221</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>225</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>231</td>\n",
       "      <td>233</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>216</td>\n",
       "      <td>217</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212</td>\n",
       "      <td>218</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>217</td>\n",
       "      <td>218</td>\n",
       "      <td>220</td>\n",
       "      <td>222</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "      <td>199</td>\n",
       "      <td>200</td>\n",
       "      <td>202</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "      <td>207</td>\n",
       "      <td>209</td>\n",
       "      <td>...</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>201</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>195</td>\n",
       "      <td>192</td>\n",
       "      <td>189</td>\n",
       "      <td>187</td>\n",
       "      <td>184</td>\n",
       "      <td>182</td>\n",
       "      <td>179</td>\n",
       "      <td>177</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18323</th>\n",
       "      <td>199</td>\n",
       "      <td>211</td>\n",
       "      <td>219</td>\n",
       "      <td>228</td>\n",
       "      <td>238</td>\n",
       "      <td>249</td>\n",
       "      <td>260</td>\n",
       "      <td>273</td>\n",
       "      <td>287</td>\n",
       "      <td>303</td>\n",
       "      <td>...</td>\n",
       "      <td>162</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>155</td>\n",
       "      <td>159</td>\n",
       "      <td>163</td>\n",
       "      <td>168</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18324</th>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>166</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>155</td>\n",
       "      <td>159</td>\n",
       "      <td>163</td>\n",
       "      <td>168</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18325</th>\n",
       "      <td>165</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>176</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18326</th>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18327</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>176</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18328 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9  ...  231  232  233  \\\n",
       "0      221  224  225  227  229  230  232  234  236  239  ...  211  212  212   \n",
       "1      218  221  222  222  225  227  229  231  233  235  ...  211  211  216   \n",
       "2      212  218  215  215  217  218  220  222  224  224  ...  202  202  202   \n",
       "3      193  196  197  199  200  202  204  205  207  209  ...  183  183  184   \n",
       "4      185  187  188  190  191  193  195  197  197  201  ...  202  195  192   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "18323  199  211  219  228  238  249  260  273  287  303  ...  162  155  157   \n",
       "18324  165  166  167  168  169  170  171  172  173  175  ...  166  155  157   \n",
       "18325  165  163  164  165  165  166  166  167  168  168  ...  178  177  176   \n",
       "18326  182  183  184  185  186  187  188  189  190  191  ...  180  179  179   \n",
       "18327  179  181  182  183  184  184  187  188  190  191  ...  174  174  174   \n",
       "\n",
       "       234  235  236  237  238  239  Label  \n",
       "0      212  212  213  214  214  215      F  \n",
       "1      217  210  211  211  212  213      F  \n",
       "2      203  203  204  204  204  205      F  \n",
       "3      184  185  185  186  187  187      F  \n",
       "4      189  187  184  182  179  177      I  \n",
       "...    ...  ...  ...  ...  ...  ...    ...  \n",
       "18323  159  151  155  159  163  168      F  \n",
       "18324  159  151  155  159  163  168      G  \n",
       "18325  175  174  173  173  172  172      I  \n",
       "18326  179  179  179  179  179  179      F  \n",
       "18327  174  174  175  175  175  176      F  \n",
       "\n",
       "[18328 rows x 241 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[(data['Label'] != 'L') & (data['Label'] != 'R') & (data['Label'] != 'H')]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d23c28f5-7333-4c42-815d-9fe66794e4d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>224</td>\n",
       "      <td>225</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>232</td>\n",
       "      <td>234</td>\n",
       "      <td>236</td>\n",
       "      <td>239</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218</td>\n",
       "      <td>221</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>225</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>231</td>\n",
       "      <td>233</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>216</td>\n",
       "      <td>217</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212</td>\n",
       "      <td>218</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>217</td>\n",
       "      <td>218</td>\n",
       "      <td>220</td>\n",
       "      <td>222</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "      <td>199</td>\n",
       "      <td>200</td>\n",
       "      <td>202</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "      <td>207</td>\n",
       "      <td>209</td>\n",
       "      <td>...</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>201</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>195</td>\n",
       "      <td>192</td>\n",
       "      <td>189</td>\n",
       "      <td>187</td>\n",
       "      <td>184</td>\n",
       "      <td>182</td>\n",
       "      <td>179</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18323</th>\n",
       "      <td>199</td>\n",
       "      <td>211</td>\n",
       "      <td>219</td>\n",
       "      <td>228</td>\n",
       "      <td>238</td>\n",
       "      <td>249</td>\n",
       "      <td>260</td>\n",
       "      <td>273</td>\n",
       "      <td>287</td>\n",
       "      <td>303</td>\n",
       "      <td>...</td>\n",
       "      <td>161</td>\n",
       "      <td>162</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>155</td>\n",
       "      <td>159</td>\n",
       "      <td>163</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18324</th>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>161</td>\n",
       "      <td>166</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>155</td>\n",
       "      <td>159</td>\n",
       "      <td>163</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18325</th>\n",
       "      <td>165</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>...</td>\n",
       "      <td>179</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>176</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18326</th>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18327</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18328 rows × 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  230  231  232  \\\n",
       "0      221  224  225  227  229  230  232  234  236  239  ...  211  211  212   \n",
       "1      218  221  222  222  225  227  229  231  233  235  ...  211  211  211   \n",
       "2      212  218  215  215  217  218  220  222  224  224  ...  202  202  202   \n",
       "3      193  196  197  199  200  202  204  205  207  209  ...  183  183  183   \n",
       "4      185  187  188  190  191  193  195  197  197  201  ...  202  202  195   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "18323  199  211  219  228  238  249  260  273  287  303  ...  161  162  155   \n",
       "18324  165  166  167  168  169  170  171  172  173  175  ...  161  166  155   \n",
       "18325  165  163  164  165  165  166  166  167  168  168  ...  179  178  177   \n",
       "18326  182  183  184  185  186  187  188  189  190  191  ...  180  180  179   \n",
       "18327  179  181  182  183  184  184  187  188  190  191  ...  174  174  174   \n",
       "\n",
       "       233  234  235  236  237  238  239  \n",
       "0      212  212  212  213  214  214  215  \n",
       "1      216  217  210  211  211  212  213  \n",
       "2      202  203  203  204  204  204  205  \n",
       "3      184  184  185  185  186  187  187  \n",
       "4      192  189  187  184  182  179  177  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "18323  157  159  151  155  159  163  168  \n",
       "18324  157  159  151  155  159  163  168  \n",
       "18325  176  175  174  173  173  172  172  \n",
       "18326  179  179  179  179  179  179  179  \n",
       "18327  174  174  174  175  175  175  176  \n",
       "\n",
       "[18328 rows x 240 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54b9362-5cd5-4798-8cfc-903a81ed9e14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign target y as the last column 'Label'\n",
    "y = data.iloc[:, -1]\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253035c5-3b25-4f4f-99d8-3b6da7146467",
   "metadata": {},
   "source": [
    "### Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f75b22d-54aa-4498-9c5b-342cdf51a3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c15d2b1c-0290-494c-b646-b4a98592b1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([147, 148, 149, 150, 151, 152, 206, 207, 208, 209, 210, 211, 212,\n",
       "       213, 214], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select 15 best features for training\n",
    "k = 15\n",
    "k_best = SelectKBest(score_func=f_classif, k=k)\n",
    "k_best.fit(X_train, y_train)\n",
    "\n",
    "selected_feature_indices = k_best.get_support(indices=True)\n",
    "selected_feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c393a69-cc25-438b-a8a0-ceebf658bea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def letters_to_colors(letters):\n",
    "    color_mapping = {\n",
    "        'F': 'blue',\n",
    "        'G': 'cyan',\n",
    "        'I': 'magenta'\n",
    "    }\n",
    "    \n",
    "    return [color_mapping.get(letter, 'black') for letter in letters]\n",
    "    \n",
    "plt.scatter(data.iloc[:, selected_feature_indices[0]], data.iloc[:, selected_feature_indices[9]], c = letters_to_colors(data.iloc[:, -1]), s=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74926c26-008b-45da-9b9c-1b09967de414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\tensor\\lib\\site-packages\\xgboost\\data.py:299: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "C:\\ProgramData\\anaconda3\\envs\\tensor\\lib\\site-packages\\xgboost\\data.py:301: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "C:\\ProgramData\\anaconda3\\envs\\tensor\\lib\\site-packages\\xgboost\\data.py:332: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "C:\\ProgramData\\anaconda3\\envs\\tensor\\lib\\site-packages\\xgboost\\data.py:323: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train.iloc[:, selected_feature_indices], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17c30547-2b1b-448c-b06e-a8a74ff6b9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of the XGBoost classifier with Sklearn SelectKBest feature selection is 0.72.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\tensor\\lib\\site-packages\\xgboost\\data.py:299: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "C:\\ProgramData\\anaconda3\\envs\\tensor\\lib\\site-packages\\xgboost\\data.py:301: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "C:\\ProgramData\\anaconda3\\envs\\tensor\\lib\\site-packages\\xgboost\\data.py:332: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "C:\\ProgramData\\anaconda3\\envs\\tensor\\lib\\site-packages\\xgboost\\data.py:323: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test.iloc[:, selected_feature_indices])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"The accuracy score of the XGBoost classifier with Sklearn SelectKBest feature selection is {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80a97f-7ec8-4f7d-9681-62a3b6b2dfe6",
   "metadata": {},
   "source": [
    "## Use LDA to do feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d22a82f-0529-4274-8b5d-a353691741f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06508042,  0.22483837],\n",
       "       [-2.59676163, -0.84923583],\n",
       "       [-0.82298288,  0.36541362],\n",
       "       ...,\n",
       "       [-1.765632  , -0.55152852],\n",
       "       [ 0.58872809,  0.29063897],\n",
       "       [-0.47529387,  3.00343185]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Use LDA to select the top 2 features\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda = lda.fit_transform(X_train, y_train)\n",
    "X_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbc39f0e-4e67-4853-81fb-94c55238067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data on Scatter plot\n",
    "# plt.scatter(data.iloc[:, selected_feature_indices[0]], data.iloc[:, selected_feature_indices[9]], c = letters_to_colors(data.iloc[:, -1]), s=8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd9fab-783a-44fb-80f4-ac2943bdb8ea",
   "metadata": {},
   "source": [
    "### Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f56ab81c-d491-419f-8350-3b1a000292fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26065bd3-f521-4af0-9a76-255eb9676657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.722 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.729 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.731 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.725 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.731 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.723 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.728 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.734 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.725 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.729 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.724 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.730 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.733 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.725 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.730 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.721 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.732 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.735 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.728 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.732 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.720 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.732 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.735 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.727 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.733 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.724 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.734 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.734 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.725 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.730 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.719 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.734 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.737 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.728 total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.734 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.719 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.733 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.736 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.726 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.735 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.723 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.732 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.736 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.725 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.734 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.713 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.725 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.733 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.722 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.723 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.715 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.722 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.734 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.723 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.725 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.712 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.718 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.730 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.722 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.721 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.714 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.723 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.736 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.723 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.726 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.714 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.721 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.737 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.724 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.727 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.708 total time=   4.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.721 total time=   4.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.731 total time=   4.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.722 total time=   4.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.719 total time=   4.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.712 total time=   4.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.723 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.737 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.726 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.728 total time=   5.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.714 total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.723 total time=   5.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.737 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.725 total time=   5.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.726 total time=   5.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.712 total time=   6.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.725 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.732 total time=   6.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.722 total time=   6.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.720 total time=   6.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.710 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.714 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.731 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.720 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.723 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.709 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.715 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.733 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.717 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.719 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.704 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.708 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.721 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.713 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.711 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.711 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.716 total time=   4.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.733 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.721 total time=   4.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.721 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.711 total time=   5.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.716 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.733 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.718 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.717 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.704 total time=   6.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.713 total time=   6.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.718 total time=   6.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.711 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.708 total time=   6.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.708 total time=   7.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.718 total time=   7.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.730 total time=   7.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.720 total time=   7.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.719 total time=   7.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.710 total time=   8.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.713 total time=   8.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.728 total time=   8.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.719 total time=   8.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.716 total time=   8.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.702 total time=   9.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.715 total time=   9.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.716 total time=   9.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.710 total time=   9.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.705 total time=   9.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.715 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.728 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.739 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.725 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.737 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.716 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.727 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.739 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.723 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.737 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.718 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.728 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.736 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.722 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.734 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.713 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.725 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.734 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.723 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.733 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.719 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.729 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.738 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.730 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.729 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.719 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.727 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.733 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.724 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.733 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.710 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.719 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.735 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.723 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.724 total time=   2.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.717 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.724 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.734 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.729 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.729 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.718 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.725 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.733 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.722 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.732 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.702 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.713 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.726 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.717 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.721 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.705 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.715 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.731 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.723 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.725 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.709 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.723 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.729 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.718 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.718 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.687 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.708 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.716 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.706 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.708 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.693 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.706 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.722 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.709 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.710 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.702 total time=   3.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.716 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.722 total time=   3.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.711 total time=   3.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.714 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.681 total time=   4.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.701 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.711 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.699 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.695 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.683 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.700 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.710 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.700 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.705 total time=   5.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.695 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.714 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.717 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.704 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.708 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.686 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.700 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.717 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.701 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.706 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.684 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.695 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.715 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.703 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.709 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.695 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.707 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.713 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.701 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.697 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.676 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.684 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.695 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.691 total time=   4.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.685 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.676 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.682 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.707 total time=   5.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.692 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.689 total time=   5.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.683 total time=   5.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.699 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.705 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.691 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.693 total time=   5.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.674 total time=   7.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.683 total time=   7.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.692 total time=   7.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.679 total time=   7.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.675 total time=   7.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.672 total time=   8.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.674 total time=   8.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.690 total time=   8.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.681 total time=   7.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.676 total time=   8.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.683 total time=   8.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.695 total time=   8.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.698 total time=   8.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.690 total time=   8.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.692 total time=   8.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.714 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.727 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.739 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.726 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.732 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.714 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.725 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.735 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.723 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.733 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.717 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.730 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.737 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.727 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.736 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.705 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.716 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.731 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.714 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.719 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.706 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.721 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.730 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.722 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.724 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.712 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.723 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.735 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.722 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.727 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.696 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.707 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.725 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.707 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.714 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.701 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.717 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.730 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.715 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.717 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.710 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.720 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.731 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.721 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.721 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.683 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.702 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.714 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.706 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.706 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.691 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.706 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.719 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.710 total time=36.0min\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.711 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.702 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.718 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.722 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.713 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.711 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.678 total time=   3.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.687 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.708 total time=   3.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.693 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.685 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.681 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.686 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.708 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.693 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.695 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.697 total time=   3.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.709 total time=   3.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.717 total time=   3.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.708 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.706 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.671 total time=   5.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.675 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.694 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.687 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.675 total time=   5.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.673 total time=   5.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.682 total time=   5.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.696 total time=   5.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.681 total time=   5.5s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.675 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.687 total time=   5.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.702 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.717 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.704 total time=   5.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.699 total time=   6.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.677 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.682 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.702 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.686 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.683 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.672 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.681 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.698 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.688 total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.686 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.687 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.699 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.702 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.695 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.693 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.669 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.671 total time=   4.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.690 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.670 total time=   4.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.671 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.666 total time=   5.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.668 total time=   5.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.684 total time=   5.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.673 total time=   5.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.670 total time=   5.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.681 total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.688 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.698 total time=   5.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.690 total time=   5.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.683 total time=   5.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.663 total time=   7.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.663 total time=   7.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.680 total time=   7.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.668 total time=   7.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.665 total time=   7.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.666 total time=   7.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.662 total time=   8.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.677 total time=   7.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.668 total time=   8.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.664 total time=   8.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.677 total time=   8.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.680 total time=   8.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.695 total time=   8.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.682 total time=   8.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.676 total time=   8.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.722 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.729 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.731 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.725 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.731 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.723 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.728 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.734 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.725 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.729 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.724 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.730 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.733 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.725 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.730 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.721 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.732 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.735 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.728 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.732 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.720 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.732 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.735 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.727 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.733 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.724 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.734 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.734 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.725 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.730 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.719 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.734 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.737 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.728 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.734 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.719 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.733 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.736 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.726 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.735 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.723 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.732 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.736 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.725 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.734 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.713 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.725 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.733 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.722 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.723 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.715 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.722 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.734 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.723 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.725 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.712 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.718 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.730 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.722 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.721 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.714 total time=   3.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.723 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.736 total time=   3.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.723 total time=   3.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.726 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.714 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.721 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.737 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.724 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.727 total time=   3.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.708 total time=   4.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.721 total time=   4.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.731 total time=   4.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.722 total time=   4.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.719 total time=   4.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.712 total time=   5.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.723 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.737 total time=   5.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.726 total time=   5.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.728 total time=   5.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.714 total time=   5.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.723 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.737 total time=   5.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.725 total time=   5.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.726 total time=   5.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.712 total time=   6.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.725 total time=   6.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.732 total time=   6.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.722 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.720 total time=   6.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.710 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.714 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.731 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.720 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.723 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.709 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.715 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.733 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.717 total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.719 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.704 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.708 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.721 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.713 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.711 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.711 total time=   4.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.716 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.733 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.721 total time=   4.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.721 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.711 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.716 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.733 total time=   5.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.718 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.717 total time=   5.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.704 total time=   6.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.713 total time=   6.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.718 total time=   6.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.711 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.708 total time=   6.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.708 total time=   7.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.718 total time=   7.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.730 total time=   7.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.720 total time=   7.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.719 total time=   7.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.710 total time=   8.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.713 total time=   8.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.728 total time=   8.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.719 total time=   8.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.716 total time=   8.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.702 total time=   9.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.715 total time=   9.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.716 total time=   9.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.710 total time=   9.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.705 total time=   9.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.715 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.728 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.739 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.725 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.737 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.716 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.727 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.739 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.723 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.737 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.718 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.728 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.736 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.722 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.734 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.713 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.725 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.734 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.723 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.733 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.719 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.729 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.738 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.730 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.729 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.719 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.727 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.733 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.724 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.733 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.710 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.719 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.735 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.723 total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.724 total time=   2.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.717 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.724 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.734 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.729 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.729 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.718 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.725 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.733 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.722 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.732 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.702 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.713 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.726 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.717 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.721 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.705 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.715 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.731 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.723 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.725 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.709 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.723 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.729 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.718 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.718 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.687 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.708 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.716 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.706 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.708 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.693 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.706 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.722 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.709 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.710 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.702 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.716 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.722 total time=   3.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.711 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.714 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.681 total time=   4.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.701 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.711 total time=   5.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.699 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.695 total time=   4.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.683 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.700 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.710 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.700 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.705 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.695 total time=   5.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.714 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.717 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.704 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.708 total time=   6.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.686 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.700 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.717 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.701 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.706 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.684 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.695 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.715 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.703 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.709 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.695 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.707 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.713 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.701 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.697 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.676 total time=   4.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.684 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.695 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.691 total time=   4.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.685 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.676 total time=   5.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.682 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.707 total time=   5.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.692 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.689 total time=   5.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.683 total time=   5.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.699 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.705 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.691 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.693 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.674 total time=   7.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.683 total time=   7.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.692 total time=   7.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.679 total time=   7.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.675 total time=   7.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.672 total time=   8.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.674 total time=   8.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.690 total time=   8.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.681 total time=   8.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.676 total time=   8.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.683 total time=   8.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.695 total time=   8.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.698 total time=   8.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.690 total time=   8.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.692 total time=   8.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.714 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.727 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.739 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.726 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.732 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.714 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.725 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.735 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.723 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.733 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.717 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.730 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.737 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.727 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.736 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.705 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.716 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.731 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.714 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.719 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.706 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.721 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.730 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.722 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.724 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.712 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.723 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.735 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.722 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.727 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.696 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.707 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.725 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.707 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.714 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.701 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.717 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.730 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.715 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.717 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.710 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.720 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.731 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.721 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.721 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.683 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.702 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.714 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.706 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.706 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.691 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.706 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.719 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.710 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.711 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.702 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.718 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.722 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.713 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.711 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.678 total time=   3.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.687 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.708 total time=   3.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.693 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.685 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.681 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.686 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.708 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.693 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.695 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.697 total time=   3.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.709 total time=   3.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.717 total time=   3.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.708 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.706 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.671 total time=   4.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.675 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.694 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.687 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.675 total time=   4.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.673 total time=   5.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.682 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.696 total time=   5.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.681 total time=   5.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.675 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.687 total time=   6.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.702 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.717 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.704 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.699 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.677 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.682 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.702 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.686 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.683 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.672 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.681 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.698 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.688 total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.686 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.687 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.699 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.702 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.695 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.693 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.669 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.671 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.690 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.670 total time=   4.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.671 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.666 total time=   5.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.668 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.684 total time=   5.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.673 total time=   5.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.670 total time=   5.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.681 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.688 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.698 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.690 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.683 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.663 total time=   7.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.663 total time=   7.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.680 total time=   7.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.668 total time=   7.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.665 total time=   7.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.666 total time=   8.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.662 total time=   8.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.677 total time=   8.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.668 total time=   8.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.664 total time=   8.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.677 total time=   8.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.680 total time=   8.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.695 total time=   8.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.682 total time=   8.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.676 total time=   8.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.723 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.736 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.740 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.722 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.5;, score=0.746 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.723 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.734 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.736 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.723 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7;, score=0.746 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.723 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.730 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.735 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.719 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.737 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.721 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.735 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.739 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.724 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.744 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.722 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.734 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.738 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.723 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7;, score=0.745 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.720 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.734 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.735 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.720 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.739 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.721 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.735 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.740 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.722 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5;, score=0.742 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.721 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.734 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.737 total time=   3.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.723 total time=   3.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7;, score=0.746 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.721 total time=   3.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.735 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.736 total time=   3.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.720 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.740 total time=   3.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.712 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.720 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.729 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.721 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.5;, score=0.735 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.716 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.718 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.726 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.723 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7;, score=0.730 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.710 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.717 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.720 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.718 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0;, score=0.726 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.713 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.720 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.729 total time=   3.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.723 total time=   3.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.729 total time=   3.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.715 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.721 total time=   4.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.727 total time=   4.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.721 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.7;, score=0.729 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.715 total time=   4.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.721 total time=   4.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.720 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.721 total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0;, score=0.730 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.711 total time=   5.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.722 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.728 total time=   5.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.721 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.5;, score=0.728 total time=   5.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.714 total time=   6.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.722 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.727 total time=   6.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.721 total time=   6.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.7;, score=0.727 total time=   6.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.714 total time=   7.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.722 total time=   7.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.721 total time=   7.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.721 total time=   7.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0;, score=0.731 total time=   7.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.710 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.718 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.715 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.717 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.5;, score=0.725 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.707 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.711 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.713 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.716 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.7;, score=0.720 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.696 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.703 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.706 total time=   3.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.708 total time=   3.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=1.0;, score=0.711 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.708 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.717 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.715 total time=   5.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.716 total time=   5.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.5;, score=0.723 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.706 total time=   6.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.710 total time=   6.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.715 total time=   6.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.713 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.7;, score=0.720 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.698 total time=   7.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.708 total time=   7.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.706 total time=   7.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.712 total time=   7.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=0.714 total time=   7.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.707 total time=   8.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.715 total time=   8.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.717 total time=   8.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.714 total time=   8.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.5;, score=0.720 total time=   7.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.705 total time=   9.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.713 total time=   9.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.714 total time=   9.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.710 total time=   9.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.7;, score=0.718 total time=   9.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.698 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.706 total time=  10.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.705 total time=  10.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.712 total time=  10.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=0.713 total time=  10.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.716 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.729 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.736 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.724 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.733 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.720 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.726 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.730 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.722 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7;, score=0.738 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.721 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.733 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.731 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.720 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.737 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.710 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.727 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.730 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.724 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.724 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.717 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.725 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.727 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.723 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7;, score=0.729 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.718 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.727 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.730 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.717 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.729 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.706 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.720 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.726 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.717 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5;, score=0.723 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.712 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.722 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.729 total time=   3.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.721 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7;, score=0.724 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.715 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.727 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.730 total time=   3.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.721 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.727 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.706 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.714 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.716 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.713 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=0.722 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.703 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.719 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.718 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.716 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7;, score=0.721 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.709 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.716 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.717 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.713 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0;, score=0.723 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.697 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.698 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.707 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.704 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.706 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.697 total time=   4.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.703 total time=   4.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.711 total time=   4.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.711 total time=   4.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.7;, score=0.708 total time=   4.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.703 total time=   4.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.708 total time=   4.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.716 total time=   4.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.708 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=0.715 total time=   4.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.687 total time=   5.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.689 total time=   5.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.700 total time=   5.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.693 total time=   5.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.5;, score=0.695 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.694 total time=   6.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.693 total time=   6.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.701 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.700 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.7;, score=0.704 total time=   6.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.698 total time=   6.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.703 total time=   6.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.717 total time=   6.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.705 total time=   6.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0;, score=0.707 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.695 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.691 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.707 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.700 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5;, score=0.706 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.693 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.699 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.711 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.705 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.7;, score=0.706 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.699 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.704 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.703 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.705 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=1.0;, score=0.709 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.689 total time=   5.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.682 total time=   5.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.694 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.692 total time=   5.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.5;, score=0.700 total time=   5.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.688 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.688 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.697 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.699 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.7;, score=0.696 total time=   6.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.688 total time=   6.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.697 total time=   6.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.705 total time=   6.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.703 total time=   6.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=0.705 total time=   6.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.680 total time=   8.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.678 total time=   8.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.689 total time=   7.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.682 total time=   8.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.5;, score=0.693 total time=   8.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.683 total time=   9.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.684 total time=   9.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.688 total time=   9.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.690 total time=   9.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=0.7;, score=0.690 total time=   9.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.687 total time=   9.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.691 total time=   9.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.700 total time=   9.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.701 total time=   9.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=0.700 total time=   9.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.715 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.724 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.727 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.726 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5;, score=0.729 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.716 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.727 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.734 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.719 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.7;, score=0.728 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.721 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.728 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.731 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.720 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.727 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.705 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.718 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.717 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.715 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.715 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.706 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.725 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.720 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.721 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7;, score=0.717 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.714 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.722 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.729 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.720 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.718 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.695 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.708 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.714 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.713 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.5;, score=0.710 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.702 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.713 total time=   3.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.724 total time=   3.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.712 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7;, score=0.711 total time=   3.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.707 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.713 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.722 total time=   3.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.716 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.711 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.692 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.703 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.704 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.704 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5;, score=0.704 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.696 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.703 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.707 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.708 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.7;, score=0.705 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.700 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.710 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.713 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.713 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0;, score=0.716 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.680 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.683 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.697 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.692 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.5;, score=0.694 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.686 total time=   4.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.688 total time=   4.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.699 total time=   4.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.696 total time=   4.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.7;, score=0.693 total time=   4.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.687 total time=   4.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.698 total time=   4.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.714 total time=   4.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.703 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=0.702 total time=   4.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.675 total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.678 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.690 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.687 total time=   5.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.5;, score=0.687 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.680 total time=   6.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.680 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.689 total time=   6.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.685 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.7;, score=0.687 total time=   6.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.682 total time=   6.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.688 total time=   6.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.707 total time=   6.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.697 total time=   6.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0;, score=0.696 total time=   6.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.683 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.687 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.691 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.689 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.5;, score=0.689 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.686 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.686 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.691 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.695 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.7;, score=0.690 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.691 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.696 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.700 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.699 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=1.0;, score=0.704 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.677 total time=   5.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.677 total time=   5.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.687 total time=   5.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.680 total time=   5.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.5;, score=0.688 total time=   5.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.677 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.677 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.677 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.681 total time=   5.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=0.7;, score=0.688 total time=   5.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.688 total time=   4.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.691 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.694 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.689 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=200, subsample=1.0;, score=0.700 total time=   5.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.673 total time=   5.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.677 total time=   6.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.683 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.676 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.5;, score=0.688 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.674 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.671 total time=   6.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.681 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.678 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=0.7;, score=0.682 total time=   6.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.684 total time=   7.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.678 total time=   7.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.692 total time=   7.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.687 total time=   7.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.2, max_depth=15, n_estimators=300, subsample=1.0;, score=0.692 total time=   7.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.5, 0.7, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [5, 10, 15],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.7, 1.0]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.5, 0.7, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [5, 10, 15],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.7, 1.0]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.5, 0.7, 1.0],\n",
       "                         'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [5, 10, 15],\n",
       "                         'n_estimators': [100, 200, 300],\n",
       "                         'subsample': [0.5, 0.7, 1.0]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a XGBoost classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, verbose=3)\n",
    "grid_search.fit(X_lda, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f68de28f-e170-443f-84d2-2108454ab3f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters are: {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters\n",
    "print(f\"The best hyperparameters are: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7c13537-8b99-4006-bc5c-047094800664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Random Forest to classify the data\n",
    "# xgb_lda = XGBClassifier()\n",
    "# xgb_lda.fit(X_lda, y_train)\n",
    "\n",
    "# Use the best hyperparameters to fit the model\n",
    "xgb_best = XGBClassifier(**grid_search.best_params_)\n",
    "xgb_best.fit(X_lda, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "215c5558-ffab-4180-87d5-14f4fabc9754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the model to make predictions on the test set\n",
    "X_test_lda = lda.transform(X_test)\n",
    "y_pred = xgb_best.predict(X_test_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe6a0ccf-15a0-4537-9af4-3c8c5608e533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of the XGBoost classifier with LDA feature selection is 0.72.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"The accuracy score of the XGBoost classifier with LDA feature selection is {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a120eba8-0a6f-4cbf-85d4-a448097ecdab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2050,  165,  103],\n",
       "       [ 401,  360,    6],\n",
       "       [ 341,    5,  235]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a075211-d6e0-4955-a8bb-1ef5b2f90c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d997a-9c86-4fca-847e-f55a1d75495c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
